{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30734,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import gc\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForQuestionAnswering, AdamW, pipeline\nfrom datasets import load_dataset\nfrom torch.utils.data import DataLoader\nfrom transformers import default_data_collator\nfrom tqdm.auto import tqdm\n\n# Clear all previous states and cache\ngc.collect()\ntorch.cuda.empty_cache()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:47:15.232233Z","iopub.execute_input":"2024-06-18T19:47:15.232818Z","iopub.status.idle":"2024-06-18T19:47:45.566113Z","shell.execute_reply.started":"2024-06-18T19:47:15.232786Z","shell.execute_reply":"2024-06-18T19:47:45.565320Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-06-18 19:47:27.563993: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-18 19:47:27.564099: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-18 19:47:27.816584: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# Step 1: PDF Extraction\ndef extract_text_from_pdf(pdf_path):\n    doc = fitz.open(pdf_path)\n    text = \"\"\n    for page_num in range(len(doc)):\n        page = doc.load_page(page_num)\n        text += page.get_text()\n    return text\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:47:45.567663Z","iopub.execute_input":"2024-06-18T19:47:45.568227Z","iopub.status.idle":"2024-06-18T19:47:45.573214Z","shell.execute_reply.started":"2024-06-18T19:47:45.568200Z","shell.execute_reply":"2024-06-18T19:47:45.572315Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Step 2: Load the SQuAD dataset\nsquad_dataset = load_dataset('squad')\n\n# Select a small subset of the dataset for quicker training\nsmall_train_dataset = squad_dataset[\"train\"].shuffle(seed=42).select(range(1000))\nsmall_eval_dataset = squad_dataset[\"validation\"].shuffle(seed=42).select(range(200))\n\n# Step 3: Load a pre-trained transformer model\nmodel_name = \"distilbert-base-cased\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_name)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:47:45.574277Z","iopub.execute_input":"2024-06-18T19:47:45.574541Z","iopub.status.idle":"2024-06-18T19:47:53.254809Z","shell.execute_reply.started":"2024-06-18T19:47:45.574518Z","shell.execute_reply":"2024-06-18T19:47:53.254003Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/7.62k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a9d2ccdaec34af48c1930105b862ceb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/14.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29ac1dacda5f445b9de52dcd0df9fb7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.82M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19f53e6d9fc04ec7a275b3a80b647244"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/87599 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9ffd893ee3c4bbb9b8a9bb49f674c88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10570 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c587e34bb88944f6928e9a1b35a9d9d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d9870caeb834914a261b44929f41f5b"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/465 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b57511ce97a342e7aee4e53a3a55c1d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c64bc13d67e4d339cdc34f2240b674c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6fc38796fff4fcab7ac41c5c6ae4f93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/263M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05315804084a4260b5969fe77a825861"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Select a small subset of the dataset for quicker training\nsmall_train_dataset = squad_dataset[\"train\"].shuffle(seed=42).select(range(40000))\nsmall_eval_dataset = squad_dataset[\"validation\"].shuffle(seed=42).select(range(8000))","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:47:53.256774Z","iopub.execute_input":"2024-06-18T19:47:53.257112Z","iopub.status.idle":"2024-06-18T19:47:53.273838Z","shell.execute_reply.started":"2024-06-18T19:47:53.257085Z","shell.execute_reply":"2024-06-18T19:47:53.272816Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# pre trained transformer model\nfrom transformers import AutoTokenizer, AutoModelForQuestionAnswering\n\nmodel_name = \"distilbert-base-cased\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_name)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:47:53.275040Z","iopub.execute_input":"2024-06-18T19:47:53.275373Z","iopub.status.idle":"2024-06-18T19:47:53.624369Z","shell.execute_reply.started":"2024-06-18T19:47:53.275341Z","shell.execute_reply":"2024-06-18T19:47:53.623602Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"def preprocess_function(examples):\n    questions = [q.strip() for q in examples[\"question\"]]\n    inputs = tokenizer(\n        questions,\n        examples[\"context\"],\n        max_length=384,\n        truncation=\"only_second\",\n        stride=128,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    offset_mapping = inputs.pop(\"offset_mapping\")\n    sample_mapping = inputs.pop(\"overflow_to_sample_mapping\")\n    answers = examples[\"answers\"]\n    start_positions = []\n    end_positions = []\n\n    for i, offsets in enumerate(offset_mapping):\n        input_ids = inputs[\"input_ids\"][i]\n        cls_index = input_ids.index(tokenizer.cls_token_id)\n\n        sequence_ids = inputs.sequence_ids(i)\n        sample_index = sample_mapping[i]\n        answers = examples[\"answers\"][sample_index]\n        if len(answers[\"answer_start\"]) == 0:\n            start_positions.append(cls_index)\n            end_positions.append(cls_index)\n        else:\n            start_char = answers[\"answer_start\"][0]\n            end_char = start_char + len(answers[\"text\"][0])\n\n            token_start_index = 0\n            while sequence_ids[token_start_index] != 1:\n                token_start_index += 1\n\n            token_end_index = len(input_ids) - 1\n            while sequence_ids[token_end_index] != 1:\n                token_end_index -= 1\n\n            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n                start_positions.append(cls_index)\n                end_positions.append(cls_index)\n            else:\n                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n                    token_start_index += 1\n                start_positions.append(token_start_index - 1)\n\n                while offsets[token_end_index][1] >= end_char:\n                    token_end_index -= 1\n                end_positions.append(token_end_index + 1)\n\n    inputs[\"start_positions\"] = start_positions\n    inputs[\"end_positions\"] = end_positions\n    return inputs\n\ntokenized_train = small_train_dataset.map(preprocess_function, batched=True, remove_columns=small_train_dataset.column_names)\ntokenized_eval = small_eval_dataset.map(preprocess_function, batched=True, remove_columns=small_eval_dataset.column_names)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:47:53.625621Z","iopub.execute_input":"2024-06-18T19:47:53.626179Z","iopub.status.idle":"2024-06-18T19:48:22.988459Z","shell.execute_reply.started":"2024-06-18T19:47:53.626145Z","shell.execute_reply":"2024-06-18T19:48:22.987609Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/40000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6af3d64068254890a46c399f66f4c306"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/8000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eff6f8f59398490aa5ffdf364e0f693c"}},"metadata":{}}]},{"cell_type":"code","source":"\nfrom torch.utils.data import DataLoader\nfrom transformers import default_data_collator, AdamW\nfrom tqdm.auto import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:48:22.989855Z","iopub.execute_input":"2024-06-18T19:48:22.990300Z","iopub.status.idle":"2024-06-18T19:48:22.995171Z","shell.execute_reply.started":"2024-06-18T19:48:22.990267Z","shell.execute_reply":"2024-06-18T19:48:22.994253Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(tokenized_train, shuffle=True, batch_size=16, collate_fn=default_data_collator)\neval_dataloader = DataLoader(tokenized_eval, batch_size=16, collate_fn=default_data_collator)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:48:22.996252Z","iopub.execute_input":"2024-06-18T19:48:22.996511Z","iopub.status.idle":"2024-06-18T19:48:24.402895Z","shell.execute_reply.started":"2024-06-18T19:48:22.996488Z","shell.execute_reply":"2024-06-18T19:48:24.402025Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr=2e-5)\n\nnum_epochs = 3\nnum_training_steps = num_epochs * (len(train_dataloader) + len(eval_dataloader))\nlr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=num_training_steps//3, gamma=0.1)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:48:24.404189Z","iopub.execute_input":"2024-06-18T19:48:24.404980Z","iopub.status.idle":"2024-06-18T19:48:24.429165Z","shell.execute_reply.started":"2024-06-18T19:48:24.404923Z","shell.execute_reply":"2024-06-18T19:48:24.428211Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nmodel.to(device)\n\nprogress_bar = tqdm(range(num_training_steps))\n\nmodel.train()\nfor epoch in range(num_epochs):\n    for batch in train_dataloader:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = model(**batch)\n        loss = outputs.loss\n        loss.backward()\n\n        optimizer.step()\n        lr_scheduler.step()\n        optimizer.zero_grad()\n        progress_bar.update(1)\n\n    model.eval()\n    with torch.no_grad():\n        for batch in eval_dataloader:\n            batch = {k: v.to(device) for k, v in batch.items()}\n            outputs = model(**batch)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:48:24.432716Z","iopub.execute_input":"2024-06-18T19:48:24.433040Z","iopub.status.idle":"2024-06-18T21:04:19.988046Z","shell.execute_reply.started":"2024-06-18T19:48:24.433015Z","shell.execute_reply":"2024-06-18T21:04:19.987077Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/9129 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce3377efd7af4a2fa30316604431a6c9"}},"metadata":{}}]},{"cell_type":"code","source":"model.save_pretrained(\"./fine-tuned-model\")\ntokenizer.save_pretrained(\"./fine-tuned-model\")\n\n# Step 8: Evaluate the Model\nqa_pipeline = pipeline('question-answering', model=\"./fine-tuned-model\", tokenizer=\"./fine-tuned-model\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T21:04:19.989185Z","iopub.execute_input":"2024-06-18T21:04:19.989515Z","iopub.status.idle":"2024-06-18T21:04:21.903520Z","shell.execute_reply.started":"2024-06-18T21:04:19.989484Z","shell.execute_reply":"2024-06-18T21:04:21.902618Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import shutil\n\n# Zip the fine-tuned model directory\nshutil.make_archive('fine-tuned-model', 'zip', './fine-tuned-model')\n\n# After running the cell, you can download the zip file from the Kaggle output\n\n    ","metadata":{"execution":{"iopub.status.busy":"2024-06-18T21:04:21.904549Z","iopub.execute_input":"2024-06-18T21:04:21.904800Z","iopub.status.idle":"2024-06-18T21:04:36.755135Z","shell.execute_reply.started":"2024-06-18T21:04:21.904777Z","shell.execute_reply":"2024-06-18T21:04:36.754197Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/fine-tuned-model.zip'"},"metadata":{}}]},{"cell_type":"code","source":"context = 'jack is a bouncer at pub'\nquestion = 'who is bouncer at pub ?'","metadata":{"execution":{"iopub.status.busy":"2024-06-18T21:20:04.622277Z","iopub.execute_input":"2024-06-18T21:20:04.622919Z","iopub.status.idle":"2024-06-18T21:20:04.626782Z","shell.execute_reply.started":"2024-06-18T21:20:04.622886Z","shell.execute_reply":"2024-06-18T21:20:04.625978Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"result = qa_pipeline(question=question, context=context)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T21:20:12.543767Z","iopub.execute_input":"2024-06-18T21:20:12.544138Z","iopub.status.idle":"2024-06-18T21:20:12.872875Z","shell.execute_reply.started":"2024-06-18T21:20:12.544106Z","shell.execute_reply":"2024-06-18T21:20:12.871658Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"print(f\"Answer: {result['answer']}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-18T21:20:52.182361Z","iopub.execute_input":"2024-06-18T21:20:52.183099Z","iopub.status.idle":"2024-06-18T21:20:52.187546Z","shell.execute_reply.started":"2024-06-18T21:20:52.183066Z","shell.execute_reply":"2024-06-18T21:20:52.186559Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Answer: jack\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install pypdf","metadata":{"execution":{"iopub.status.busy":"2024-06-18T21:12:55.906190Z","iopub.execute_input":"2024-06-18T21:12:55.906612Z","iopub.status.idle":"2024-06-18T21:13:11.055977Z","shell.execute_reply.started":"2024-06-18T21:12:55.906572Z","shell.execute_reply":"2024-06-18T21:13:11.054722Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: pypdf in /opt/conda/lib/python3.10/site-packages (4.2.0)\nRequirement already satisfied: typing_extensions>=4.0 in /opt/conda/lib/python3.10/site-packages (from pypdf) (4.9.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from pypdf import PdfReader","metadata":{"execution":{"iopub.status.busy":"2024-06-18T21:14:26.582304Z","iopub.execute_input":"2024-06-18T21:14:26.582665Z","iopub.status.idle":"2024-06-18T21:14:26.586828Z","shell.execute_reply.started":"2024-06-18T21:14:26.582635Z","shell.execute_reply":"2024-06-18T21:14:26.585999Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def extract_text_from_pdf(pdf_path):\n  extr = PdfReader(pdf_path)\n  text = ''\n  for i in range(14,18):\n    page = extr.pages[i]\n    text_p = page.extract_text()\n    text += text_p\n  return text","metadata":{"execution":{"iopub.status.busy":"2024-06-18T21:14:37.983073Z","iopub.execute_input":"2024-06-18T21:14:37.983909Z","iopub.status.idle":"2024-06-18T21:14:37.989357Z","shell.execute_reply.started":"2024-06-18T21:14:37.983871Z","shell.execute_reply":"2024-06-18T21:14:37.988340Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}